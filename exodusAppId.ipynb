{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2849,
     "status": "ok",
     "timestamp": 1607848320248,
     "user": {
      "displayName": "Luis Manuel Molina Coca",
      "photoUrl": "",
      "userId": "18301587923796676536"
     },
     "user_tz": -60
    },
    "id": "81KMSjML8-xM"
   },
   "outputs": [],
   "source": [
    "import time\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import regex as re\r\n",
    "import requests\r\n",
    "import pandas as pd\r\n",
    "from skimage import io, transform\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sys\r\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1607848323926,
     "user": {
      "displayName": "Luis Manuel Molina Coca",
      "photoUrl": "",
      "userId": "18301587923796676536"
     },
     "user_tz": -60
    },
    "id": "fDj0ljbH-Lzn"
   },
   "outputs": [],
   "source": [
    "def cargarElementosTratados(rutaDataSet):\r\n",
    "    try:\r\n",
    "        df = pd.read_csv(rutaDataSet, header = None, names = ['id', 'appId'])\r\n",
    "        data_list = list(df['id'])\r\n",
    "    except Exception as e:\r\n",
    "        data_list = []\r\n",
    "\r\n",
    "    return data_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1607848325683,
     "user": {
      "displayName": "Luis Manuel Molina Coca",
      "photoUrl": "",
      "userId": "18301587923796676536"
     },
     "user_tz": -60
    },
    "id": "MEpDOeoJRU3D"
   },
   "outputs": [],
   "source": [
    "def crearListaElementosATratar(tratados, inicio = 1, limite = 100):\r\n",
    "    lista = list(range(inicio, inicio + limite))\r\n",
    "    \r\n",
    "    return [x for x in lista if x not in tratados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1607848328501,
     "user": {
      "displayName": "Luis Manuel Molina Coca",
      "photoUrl": "",
      "userId": "18301587923796676536"
     },
     "user_tz": -60
    },
    "id": "a8VUq-cSBTF2"
   },
   "outputs": [],
   "source": [
    "def rastrearHtml(html):\r\n",
    "    appId = 'na'\r\n",
    "    soup = BeautifulSoup(html, features='lxml')\r\n",
    "  \r\n",
    "    #Id de la aplicación\r\n",
    "    try:\r\n",
    "        tag = soup.find('a', {'class': 'link main-link'})\r\n",
    "        appId = tag['href'][tag['href'].find('=') + 1:] \r\n",
    "    except Exception as e:\r\n",
    "        appId = 'na'\r\n",
    "\r\n",
    "    return appId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 950
    },
    "executionInfo": {
     "elapsed": 40626492,
     "status": "error",
     "timestamp": 1607888996130,
     "user": {
      "displayName": "Luis Manuel Molina Coca",
      "photoUrl": "",
      "userId": "18301587923796676536"
     },
     "user_tz": -60
    },
    "id": "r_zcFvDF9V27",
    "outputId": "77792e44-35ee-4170-f07b-97bc313ab36e"
   },
   "outputs": [],
   "source": [
    "HEADER = {\r\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\r\n",
    "    \"Accept-Encoding\": \"gzip, deflate, sdch, br\",\r\n",
    "    \"Accept-Language\": \"en-US,en;q=0.8\",\r\n",
    "    \"Cache-Control\": \"no-cache\",\r\n",
    "    \"dnt\": \"1\",\r\n",
    "    \"Pragma\": \"no-cache\",\r\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\r\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"\r\n",
    "}\r\n",
    "URL_BASE = 'https://reports.exodus-privacy.eu.org/es/reports/'\r\n",
    "fichero = '/content/drive/MyDrive/exodus/exodusAppId.csv'\r\n",
    "INICIO = 1\r\n",
    "LIMITE = 153373\r\n",
    "\r\n",
    "#Inicializar lista de los elementos ya tratados a partir del json del dataset.\r\n",
    "tratados_list = cargarElementosTratados(fichero)\r\n",
    "#Inicializar índice de elementos\r\n",
    "elem = 0\r\n",
    "#Crear lista de elementos a tratar(Serie_elementos_tratados, inicio, limite)\r\n",
    "lista = crearListaElementosATratar(tratados_list, INICIO, LIMITE)\r\n",
    "#Crear el diccionario donde se recogeran los elementos procesados de la sesión.\r\n",
    "scrap_json = {}\r\n",
    "\r\n",
    "while elem < len(lista): #Mientras existan elementos en la lista\r\n",
    "    web = None\r\n",
    "    url = URL_BASE + str(lista[elem]) + '/'\r\n",
    "\r\n",
    "    try: #Manejo de posibles excepciones causadas por la petición de la página gestionando tiempos, repeticiones o paradas\r\n",
    "        web = requests.get(url, headers = HEADER)\r\n",
    "    except requests.exceptions.ConnectionError as e:\r\n",
    "        print('Error de conexión procesando ' + url + '. ' + str(e))\r\n",
    "    except requests.exceptions.ConnectTimeout as e:\r\n",
    "        print('Error de conexión procesando ' + url + '. ' + str(e))\r\n",
    "    except requests.exceptions.ProxyError as e:\r\n",
    "        print('Error fatal de proxy procesando ' + url + '. ' + str(e))\r\n",
    "    except requests.exceptions.SSLError as e:\r\n",
    "        print('Error fatal de SSL procesando ' + url + '. ' + str(e))\r\n",
    "    except Exception as e:\r\n",
    "        print('Error fatal no controlado procesando ' + url + '. ' + str(e))\r\n",
    "\r\n",
    "    if web != None: #Si se ha recuperado información del servidor, comprobamos su status.\r\n",
    "        if (web.status_code >= 500) and (web.status_code < 600): #Errores en el servidor\r\n",
    "            print('Error ' + str(web.status_code) + ' de servidor producido en la request procesando ' + url)\r\n",
    "            elem += 1\r\n",
    "        if (web.status_code >= 400) and (web.status_code < 500): #Errores en el cliente > Avisar y volvemos a intentarlo tras un tiempo hasta agotar intentos y pasar al siguiente\r\n",
    "            print('Error ' + str(web.status_code) + ' de cliente producido en la request procesando ' + url)\r\n",
    "            elem += 1\r\n",
    "        if (web.status_code >= 300) and (web.status_code < 400): #Errores de redirección > Paramos el rastreo de esta url y seguimos.\r\n",
    "            print('Error ' + str(web.status_code) + ' de redirección en la request procesando ' + url)\r\n",
    "            elem += 1\r\n",
    "        if (web.status_code > 200) and (web.status_code < 300): #Petición correcta con incidencias > Avisar y volvemos a intentarlo tras un tiempo hasta agotar intentos y pasar al siguiente.\r\n",
    "            print('Incidencia ' + str(web.status_code) + ' tras petición correcta procesando  ' + url)\r\n",
    "            elem += 1\r\n",
    "        if web.status_code == 200: #Petición correcta y html a nuestra disposición\r\n",
    "            app = rastrearHtml(web.content)\r\n",
    "            if app != 'na': #Si se ha procesado la web correctamente y extraído la información\r\n",
    "                fila = [str(lista[elem]), app]\r\n",
    "                with open(fichero, 'a', newline = '') as f:\r\n",
    "                    writer = csv.writer(f)\r\n",
    "                    writer.writerow(fila)\r\n",
    "                f.close()\r\n",
    "                elem += 1\r\n",
    "                #print('Rastreada url ' + url + ' con éxito')\r\n",
    "                time.sleep(0.5)\r\n",
    "            else: #Si no se ha procesado por un fallo del parseador del html se apunta la incidencia y se procede con el siguiente\r\n",
    "                elem += 1\r\n",
    "    else: #Si no se ha recuperado información del servidor\r\n",
    "        elem += 1\r\n",
    "\r\n",
    "print('Rastreo finalizado')\r\n",
    "\r\n",
    "#Actualizar el diccionario de los elmentos ya tratados con los rastreados en esta sesión y guardar el dataset y las incidencias\r\n",
    "#tratados_dict.update(scrap_json)\r\n",
    "#\r\n",
    "#try:\r\n",
    "#    with open(fichero, 'w') as outfile: #Al acabar, volcar el nuevo fichero con el dataset.\r\n",
    "#        json.dump(tratados_dict, outfile)\r\n",
    "#except Exception as e:\r\n",
    "#    print('Error escribiendo dataset')\r\n",
    "#    print(e)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMYcFAeFnfmrKrfTxZ3WwNc",
   "collapsed_sections": [],
   "mount_file_id": "1q8dkjAjOBqD1sI619tAuLt06qV9r48pY",
   "name": "exodusAppId.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
